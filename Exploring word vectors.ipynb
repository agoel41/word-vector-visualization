{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "Install gensim using the following command\n",
    "\n",
    "```pip install gensim```\n",
    "\n",
    "Install or update NLTK module\n",
    "\n",
    "```\n",
    "pip install --user -U nltk\n",
    "pip install --upgrade nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "***Reuters Corpus***\n",
    "\n",
    "The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into two sets, called \"training\" and \"test\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- https://www.nltk.org/install.html\n",
    "- https://www.nltk.org/data.html\n",
    "- https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/agoel/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import sys\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 5\n",
    "print(sys.version_info)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "# Download Reuters corpus from NLTK data distribution\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Reuters corpus\n",
    "\n",
    "Unlike the Brown Corpus, categories in the Reuters corpus overlap with each other, simply because a news story often covers multiple topics. We can ask for the topics covered by one or more documents, or for the documents included in one or more categories. For convenience, the corpus methods accept a single fileid or a list of fileids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', 'test/14840', 'test/14841', 'test/14842', 'test/14843']\n",
      "News documents count: 10788\n"
     ]
    }
   ],
   "source": [
    "# The text with fileid 'test/14826' is a document drawn from the test set.\n",
    "print(reuters.fileids()[0:10])\n",
    "# News document count\n",
    "print('News documents count: {}'.format(len(reuters.fileids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories count: 90\n",
      "\n",
      "Categories: ['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr']\n",
      "\n",
      "Categories in the document 'training/9865': ['barley', 'corn', 'grain', 'wheat']\n",
      "\n",
      "['test/15618', 'test/15649', 'test/15676', 'test/15728', 'test/15871', 'test/15875', 'test/15952', 'test/17767', 'test/17769', 'test/18024']\n",
      "\n",
      "Words by document/file: ['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', 'BIDS', 'DETAILED', 'French', 'operators', 'have', 'requested', 'licences', 'to', 'export']\n",
      "\n",
      "Words by categories: ['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]\n",
      "\n",
      "Words by multiple categories: ['THAI', 'TRADE', 'DEFICIT', 'WIDENS', 'IN', 'FIRST', ...]\n"
     ]
    }
   ],
   "source": [
    "print('categories count: {}'.format(len(reuters.categories())), end='\\n\\n')\n",
    "print('Categories: {}'.format(reuters.categories()[0:20]), end='\\n\\n')\n",
    "print('Categories in the document \\'training/9865\\': {}'.format(reuters.categories('training/9865')), end='\\n\\n')\n",
    "print(reuters.fileids('barley')[0:10], end='\\n\\n')\n",
    "print('Words by document/file: {}'.format(reuters.words('training/9865')[:14]), end='\\n\\n')\n",
    "print('Words by categories: {}'.format(reuters.words(categories='barley')), end='\\n\\n')\n",
    "print('Words by multiple categories: {}'.format(reuters.words(categories=['barley', 'corn'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurrence\n",
    "\n",
    "A co-occurrence matrix counts how often things co-occur in some environment. Given some word $w_i$  occurring in the document, we consider the context window surrounding $w_i$. Supposing our fixed window size is n, then this is the n preceding and n subsequent words in that document, i.e. words  $w_{i-n}…w_{i-1}$  and  $w_{i+1}…w_{i+n}$ . We build a co-occurrence matrix M, which is a symmetric word-by-word matrix in which  $M_{ij}$  is the number of times $w_{j}$ appears inside  $w_{i}$'s window.words\n",
    "\n",
    "***Example: Co-Occurrence with Fixed Window of n=1:***\n",
    "\n",
    "Document 1: \"all that glitters is not gold\"\n",
    "\n",
    "Document 2: \"all is well that ends well\"\n",
    "\n",
    "![title](static/co_occurence_matrix.png)\n",
    "\n",
    "\n",
    "The rows (or columns) of this matrix provide one type of word vectors (those based on word-word co-occurrence), but the vectors will be large in general (linear in the number of distinct words in a corpus). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Co-Occurrence Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(category='crude'):\n",
    "    \n",
    "    \"\"\" Read files from the specified Reuter's category.\n",
    "        Params:\n",
    "            category (string): category name\n",
    "        Return:\n",
    "            list of lists, with words from each of the processed files\n",
    "    \"\"\"\n",
    "    \n",
    "    files = reuters.fileids(category)\n",
    "    return [[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<START>', 'japan', 'to', 'revise', 'long', '-', 'term', 'energy', 'demand',\n",
      "  'downwards', 'the', 'ministry', 'of', 'international', 'trade', 'and', 'industry', '(',\n",
      "  'miti', ')', 'will', 'revise', 'its', 'long', '-', 'term', 'energy', 'supply', '/',\n",
      "  'demand', 'outlook', 'by', 'august', 'to', 'meet', 'a', 'forecast', 'downtrend', 'in',\n",
      "  'japanese', 'energy', 'demand', ',', 'ministry', 'officials', 'said', '.', 'miti', 'is',\n",
      "  'expected', 'to', 'lower', 'the', 'projection', 'for', 'primary', 'energy', 'supplies',\n",
      "  'in', 'the', 'year', '2000', 'to', '550', 'mln', 'kilolitres', '(', 'kl', ')', 'from',\n",
      "  '600', 'mln', ',', 'they', 'said', '.', 'the', 'decision', 'follows', 'the',\n",
      "  'emergence', 'of', 'structural', 'changes', 'in', 'japanese', 'industry', 'following',\n",
      "  'the', 'rise', 'in', 'the', 'value', 'of', 'the', 'yen', 'and', 'a', 'decline', 'in',\n",
      "  'domestic', 'electric', 'power', 'demand', '.', 'miti', 'is', 'planning', 'to', 'work',\n",
      "  'out', 'a', 'revised', 'energy', 'supply', '/', 'demand', 'outlook', 'through',\n",
      "  'deliberations', 'of', 'committee', 'meetings', 'of', 'the', 'agency', 'of', 'natural',\n",
      "  'resources', 'and', 'energy', ',', 'the', 'officials', 'said', '.', 'they', 'said',\n",
      "  'miti', 'will', 'also', 'review', 'the', 'breakdown', 'of', 'energy', 'supply',\n",
      "  'sources', ',', 'including', 'oil', ',', 'nuclear', ',', 'coal', 'and', 'natural',\n",
      "  'gas', '.', 'nuclear', 'energy', 'provided', 'the', 'bulk', 'of', 'japan', \"'\", 's',\n",
      "  'electric', 'power', 'in', 'the', 'fiscal', 'year', 'ended', 'march', '31', ',',\n",
      "  'supplying', 'an', 'estimated', '27', 'pct', 'on', 'a', 'kilowatt', '/', 'hour',\n",
      "  'basis', ',', 'followed', 'by', 'oil', '(', '23', 'pct', ')', 'and', 'liquefied',\n",
      "  'natural', 'gas', '(', '21', 'pct', '),', 'they', 'noted', '.', '<END>'],\n",
      " ['<START>', 'energy', '/', 'u', '.', 's', '.', 'petrochemical', 'industry', 'cheap',\n",
      "  'oil', 'feedstocks', ',', 'the', 'weakened', 'u', '.', 's', '.', 'dollar', 'and', 'a',\n",
      "  'plant', 'utilization', 'rate', 'approaching', '90', 'pct', 'will', 'propel', 'the',\n",
      "  'streamlined', 'u', '.', 's', '.', 'petrochemical', 'industry', 'to', 'record',\n",
      "  'profits', 'this', 'year', ',', 'with', 'growth', 'expected', 'through', 'at', 'least',\n",
      "  '1990', ',', 'major', 'company', 'executives', 'predicted', '.', 'this', 'bullish',\n",
      "  'outlook', 'for', 'chemical', 'manufacturing', 'and', 'an', 'industrywide', 'move',\n",
      "  'to', 'shed', 'unrelated', 'businesses', 'has', 'prompted', 'gaf', 'corp', '&', 'lt',\n",
      "  ';', 'gaf', '>,', 'privately', '-', 'held', 'cain', 'chemical', 'inc', ',', 'and',\n",
      "  'other', 'firms', 'to', 'aggressively', 'seek', 'acquisitions', 'of', 'petrochemical',\n",
      "  'plants', '.', 'oil', 'companies', 'such', 'as', 'ashland', 'oil', 'inc', '&', 'lt',\n",
      "  ';', 'ash', '>,', 'the', 'kentucky', '-', 'based', 'oil', 'refiner', 'and', 'marketer',\n",
      "  ',', 'are', 'also', 'shopping', 'for', 'money', '-', 'making', 'petrochemical',\n",
      "  'businesses', 'to', 'buy', '.', '\"', 'i', 'see', 'us', 'poised', 'at', 'the',\n",
      "  'threshold', 'of', 'a', 'golden', 'period', ',\"', 'said', 'paul', 'oreffice', ',',\n",
      "  'chairman', 'of', 'giant', 'dow', 'chemical', 'co', '&', 'lt', ';', 'dow', '>,',\n",
      "  'adding', ',', '\"', 'there', \"'\", 's', 'no', 'major', 'plant', 'capacity', 'being',\n",
      "  'added', 'around', 'the', 'world', 'now', '.', 'the', 'whole', 'game', 'is', 'bringing',\n",
      "  'out', 'new', 'products', 'and', 'improving', 'the', 'old', 'ones', '.\"', 'analysts',\n",
      "  'say', 'the', 'chemical', 'industry', \"'\", 's', 'biggest', 'customers', ',',\n",
      "  'automobile', 'manufacturers', 'and', 'home', 'builders', 'that', 'use', 'a', 'lot',\n",
      "  'of', 'paints', 'and', 'plastics', ',', 'are', 'expected', 'to', 'buy', 'quantities',\n",
      "  'this', 'year', '.', 'u', '.', 's', '.', 'petrochemical', 'plants', 'are', 'currently',\n",
      "  'operating', 'at', 'about', '90', 'pct', 'capacity', ',', 'reflecting', 'tighter',\n",
      "  'supply', 'that', 'could', 'hike', 'product', 'prices', 'by', '30', 'to', '40', 'pct',\n",
      "  'this', 'year', ',', 'said', 'john', 'dosher', ',', 'managing', 'director', 'of',\n",
      "  'pace', 'consultants', 'inc', 'of', 'houston', '.', 'demand', 'for', 'some', 'products',\n",
      "  'such', 'as', 'styrene', 'could', 'push', 'profit', 'margins', 'up', 'by', 'as', 'much',\n",
      "  'as', '300', 'pct', ',', 'he', 'said', '.', 'oreffice', ',', 'speaking', 'at', 'a',\n",
      "  'meeting', 'of', 'chemical', 'engineers', 'in', 'houston', ',', 'said', 'dow', 'would',\n",
      "  'easily', 'top', 'the', '741', 'mln', 'dlrs', 'it', 'earned', 'last', 'year', 'and',\n",
      "  'predicted', 'it', 'would', 'have', 'the', 'best', 'year', 'in', 'its', 'history', '.',\n",
      "  'in', '1985', ',', 'when', 'oil', 'prices', 'were', 'still', 'above', '25', 'dlrs', 'a',\n",
      "  'barrel', 'and', 'chemical', 'exports', 'were', 'adversely', 'affected', 'by', 'the',\n",
      "  'strong', 'u', '.', 's', '.', 'dollar', ',', 'dow', 'had', 'profits', 'of', '58', 'mln',\n",
      "  'dlrs', '.', '\"', 'i', 'believe', 'the', 'entire', 'chemical', 'industry', 'is',\n",
      "  'headed', 'for', 'a', 'record', 'year', 'or', 'close', 'to', 'it', ',\"', 'oreffice',\n",
      "  'said', '.', 'gaf', 'chairman', 'samuel', 'heyman', 'estimated', 'that', 'the', 'u',\n",
      "  '.', 's', '.', 'chemical', 'industry', 'would', 'report', 'a', '20', 'pct', 'gain',\n",
      "  'in', 'profits', 'during', '1987', '.', 'last', 'year', ',', 'the', 'domestic',\n",
      "  'industry', 'earned', 'a', 'total', 'of', '13', 'billion', 'dlrs', ',', 'a', '54',\n",
      "  'pct', 'leap', 'from', '1985', '.', 'the', 'turn', 'in', 'the', 'fortunes', 'of', 'the',\n",
      "  'once', '-', 'sickly', 'chemical', 'industry', 'has', 'been', 'brought', 'about', 'by',\n",
      "  'a', 'combination', 'of', 'luck', 'and', 'planning', ',', 'said', 'pace', \"'\", 's',\n",
      "  'john', 'dosher', '.', 'dosher', 'said', 'last', 'year', \"'\", 's', 'fall', 'in', 'oil',\n",
      "  'prices', 'made', 'feedstocks', 'dramatically', 'cheaper', 'and', 'at', 'the', 'same',\n",
      "  'time', 'the', 'american', 'dollar', 'was', 'weakening', 'against', 'foreign',\n",
      "  'currencies', '.', 'that', 'helped', 'boost', 'u', '.', 's', '.', 'chemical', 'exports',\n",
      "  '.', 'also', 'helping', 'to', 'bring', 'supply', 'and', 'demand', 'into', 'balance',\n",
      "  'has', 'been', 'the', 'gradual', 'market', 'absorption', 'of', 'the', 'extra',\n",
      "  'chemical', 'manufacturing', 'capacity', 'created', 'by', 'middle', 'eastern', 'oil',\n",
      "  'producers', 'in', 'the', 'early', '1980s', '.', 'finally', ',', 'virtually', 'all',\n",
      "  'major', 'u', '.', 's', '.', 'chemical', 'manufacturers', 'have', 'embarked', 'on',\n",
      "  'an', 'extensive', 'corporate', 'restructuring', 'program', 'to', 'mothball',\n",
      "  'inefficient', 'plants', ',', 'trim', 'the', 'payroll', 'and', 'eliminate', 'unrelated',\n",
      "  'businesses', '.', 'the', 'restructuring', 'touched', 'off', 'a', 'flurry', 'of',\n",
      "  'friendly', 'and', 'hostile', 'takeover', 'attempts', '.', 'gaf', ',', 'which', 'made',\n",
      "  'an', 'unsuccessful', 'attempt', 'in', '1985', 'to', 'acquire', 'union', 'carbide',\n",
      "  'corp', '&', 'lt', ';', 'uk', '>,', 'recently', 'offered', 'three', 'billion', 'dlrs',\n",
      "  'for', 'borg', 'warner', 'corp', '&', 'lt', ';', 'bor', '>,', 'a', 'chicago',\n",
      "  'manufacturer', 'of', 'plastics', 'and', 'chemicals', '.', 'another', 'industry',\n",
      "  'powerhouse', ',', 'w', '.', 'r', '.', 'grace', '&', 'lt', ';', 'gra', '>', 'has',\n",
      "  'divested', 'its', 'retailing', ',', 'restaurant', 'and', 'fertilizer', 'businesses',\n",
      "  'to', 'raise', 'cash', 'for', 'chemical', 'acquisitions', '.', 'but', 'some', 'experts',\n",
      "  'worry', 'that', 'the', 'chemical', 'industry', 'may', 'be', 'headed', 'for', 'trouble',\n",
      "  'if', 'companies', 'continue', 'turning', 'their', 'back', 'on', 'the', 'manufacturing',\n",
      "  'of', 'staple', 'petrochemical', 'commodities', ',', 'such', 'as', 'ethylene', ',',\n",
      "  'in', 'favor', 'of', 'more', 'profitable', 'specialty', 'chemicals', 'that', 'are',\n",
      "  'custom', '-', 'designed', 'for', 'a', 'small', 'group', 'of', 'buyers', '.', '\"',\n",
      "  'companies', 'like', 'dupont', '&', 'lt', ';', 'dd', '>', 'and', 'monsanto', 'co', '&',\n",
      "  'lt', ';', 'mtc', '>', 'spent', 'the', 'past', 'two', 'or', 'three', 'years', 'trying',\n",
      "  'to', 'get', 'out', 'of', 'the', 'commodity', 'chemical', 'business', 'in', 'reaction',\n",
      "  'to', 'how', 'badly', 'the', 'market', 'had', 'deteriorated', ',\"', 'dosher', 'said',\n",
      "  '.', '\"', 'but', 'i', 'think', 'they', 'will', 'eventually', 'kill', 'the', 'margins',\n",
      "  'on', 'the', 'profitable', 'chemicals', 'in', 'the', 'niche', 'market', '.\"', 'some',\n",
      "  'top', 'chemical', 'executives', 'share', 'the', 'concern', '.', '\"', 'the',\n",
      "  'challenge', 'for', 'our', 'industry', 'is', 'to', 'keep', 'from', 'getting', 'carried',\n",
      "  'away', 'and', 'repeating', 'past', 'mistakes', ',\"', 'gaf', \"'\", 's', 'heyman',\n",
      "  'cautioned', '.', '\"', 'the', 'shift', 'from', 'commodity', 'chemicals', 'may', 'be',\n",
      "  'ill', '-', 'advised', '.', 'specialty', 'businesses', 'do', 'not', 'stay', 'special',\n",
      "  'long', '.\"', 'houston', '-', 'based', 'cain', 'chemical', ',', 'created', 'this',\n",
      "  'month', 'by', 'the', 'sterling', 'investment', 'banking', 'group', ',', 'believes',\n",
      "  'it', 'can', 'generate', '700', 'mln', 'dlrs', 'in', 'annual', 'sales', 'by', 'bucking',\n",
      "  'the', 'industry', 'trend', '.', 'chairman', 'gordon', 'cain', ',', 'who', 'previously',\n",
      "  'led', 'a', 'leveraged', 'buyout', 'of', 'dupont', \"'\", 's', 'conoco', 'inc', \"'\", 's',\n",
      "  'chemical', 'business', ',', 'has', 'spent', '1', '.', '1', 'billion', 'dlrs', 'since',\n",
      "  'january', 'to', 'buy', 'seven', 'petrochemical', 'plants', 'along', 'the', 'texas',\n",
      "  'gulf', 'coast', '.', 'the', 'plants', 'produce', 'only', 'basic', 'commodity',\n",
      "  'petrochemicals', 'that', 'are', 'the', 'building', 'blocks', 'of', 'specialty',\n",
      "  'products', '.', '\"', 'this', 'kind', 'of', 'commodity', 'chemical', 'business', 'will',\n",
      "  'never', 'be', 'a', 'glamorous', ',', 'high', '-', 'margin', 'business', ',\"', 'cain',\n",
      "  'said', ',', 'adding', 'that', 'demand', 'is', 'expected', 'to', 'grow', 'by', 'about',\n",
      "  'three', 'pct', 'annually', '.', 'garo', 'armen', ',', 'an', 'analyst', 'with', 'dean',\n",
      "  'witter', 'reynolds', ',', 'said', 'chemical', 'makers', 'have', 'also', 'benefitted',\n",
      "  'by', 'increasing', 'demand', 'for', 'plastics', 'as', 'prices', 'become', 'more',\n",
      "  'competitive', 'with', 'aluminum', ',', 'wood', 'and', 'steel', 'products', '.',\n",
      "  'armen', 'estimated', 'the', 'upturn', 'in', 'the', 'chemical', 'business', 'could',\n",
      "  'last', 'as', 'long', 'as', 'four', 'or', 'five', 'years', ',', 'provided', 'the', 'u',\n",
      "  '.', 's', '.', 'economy', 'continues', 'its', 'modest', 'rate', 'of', 'growth', '.',\n",
      "  '<END>'],\n",
      " ['<START>', 'turkey', 'calls', 'for', 'dialogue', 'to', 'solve', 'dispute', 'turkey',\n",
      "  'said', 'today', 'its', 'disputes', 'with', 'greece', ',', 'including', 'rights', 'on',\n",
      "  'the', 'continental', 'shelf', 'in', 'the', 'aegean', 'sea', ',', 'should', 'be',\n",
      "  'solved', 'through', 'negotiations', '.', 'a', 'foreign', 'ministry', 'statement',\n",
      "  'said', 'the', 'latest', 'crisis', 'between', 'the', 'two', 'nato', 'members',\n",
      "  'stemmed', 'from', 'the', 'continental', 'shelf', 'dispute', 'and', 'an', 'agreement',\n",
      "  'on', 'this', 'issue', 'would', 'effect', 'the', 'security', ',', 'economy', 'and',\n",
      "  'other', 'rights', 'of', 'both', 'countries', '.', '\"', 'as', 'the', 'issue', 'is',\n",
      "  'basicly', 'political', ',', 'a', 'solution', 'can', 'only', 'be', 'found', 'by',\n",
      "  'bilateral', 'negotiations', ',\"', 'the', 'statement', 'said', '.', 'greece', 'has',\n",
      "  'repeatedly', 'said', 'the', 'issue', 'was', 'legal', 'and', 'could', 'be', 'solved',\n",
      "  'at', 'the', 'international', 'court', 'of', 'justice', '.', 'the', 'two', 'countries',\n",
      "  'approached', 'armed', 'confrontation', 'last', 'month', 'after', 'greece', 'announced',\n",
      "  'it', 'planned', 'oil', 'exploration', 'work', 'in', 'the', 'aegean', 'and', 'turkey',\n",
      "  'said', 'it', 'would', 'also', 'search', 'for', 'oil', '.', 'a', 'face', '-', 'off',\n",
      "  'was', 'averted', 'when', 'turkey', 'confined', 'its', 'research', 'to', 'territorrial',\n",
      "  'waters', '.', '\"', 'the', 'latest', 'crises', 'created', 'an', 'historic',\n",
      "  'opportunity', 'to', 'solve', 'the', 'disputes', 'between', 'the', 'two', 'countries',\n",
      "  ',\"', 'the', 'foreign', 'ministry', 'statement', 'said', '.', 'turkey', \"'\", 's',\n",
      "  'ambassador', 'in', 'athens', ',', 'nazmi', 'akiman', ',', 'was', 'due', 'to', 'meet',\n",
      "  'prime', 'minister', 'andreas', 'papandreou', 'today', 'for', 'the', 'greek', 'reply',\n",
      "  'to', 'a', 'message', 'sent', 'last', 'week', 'by', 'turkish', 'prime', 'minister',\n",
      "  'turgut', 'ozal', '.', 'the', 'contents', 'of', 'the', 'message', 'were', 'not',\n",
      "  'disclosed', '.', '<END>']]\n"
     ]
    }
   ],
   "source": [
    "reuters_corpus = read_corpus()\n",
    "pprint.pprint(reuters_corpus[:3], compact=True, width=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find distinct words in a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a method to work out the distinct words (word types) that occur in the corpus. We can do this with for loops, but it's more efficient to do it with Python list comprehensions. In particular, please refer to [this](http://web.stanford.edu/class/cs224n/assignments/a1_preview/exploring_word_vectors.html) to flatten a list of lists. For more information on list comprehensions, please refer [here](https://coderwall.com/p/rcmaea/flatten-a-list-of-lists-in-one-line-in-python)\n",
    "\n",
    "You may find it useful to use [Python sets](https://www.w3schools.com/python/python_sets.asp) to remove duplicate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_words(corpus):\n",
    "    \n",
    "    \"\"\" Determine a list of distinct words for the corpus.\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "        Return:\n",
    "            corpus_words (list of strings): list of distinct words across the corpus, sorted (using python 'sorted' function)\n",
    "            num_corpus_words (integer): number of distinct words across the corpus\n",
    "    \"\"\"\n",
    "    corpus_words = []\n",
    "    num_corpus_words = -1\n",
    "    \n",
    "    \"\"\"List comprehensions are cleaner and faster than the for loop\n",
    "       A set is a collection which is unordered, unindexed and contains unique elements. \n",
    "      In Python sets are written with curly brackets.\n",
    "    \"\"\"\n",
    "    corpus_set = {w for s in corpus for w in s}\n",
    "    sorted_corpus_set = sorted(corpus_set)\n",
    "    corpus_words = sorted_corpus_set\n",
    "    num_corpus_words = len(corpus_words)\n",
    "    \n",
    "    return corpus_words, num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define toy corpus\n",
    "test_corpus = [\"START All that glitters isn't gold END\".split(\" \"), \"START All's well that ends well END\".split(\" \")]\n",
    "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
    "\n",
    "# Correct answers\n",
    "ans_test_corpus_words = sorted(list(set([\"START\", \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", \"END\"])))\n",
    "ans_num_corpus_words = len(ans_test_corpus_words)\n",
    "\n",
    "# Test correct number of words\n",
    "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
    "\n",
    "# Test correct words\n",
    "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours:   {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
    "\n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute co-occurence matrix\n",
    "\n",
    "Below is a method that constructs a co-occurrence matrix for a certain window-size n (with a default of 4), considering words n  before and n  after the word in the center of the window. Here, we will use numpy (np) to represent vectors, matrices, and tensors. If  not familiar with NumPy, there's a NumPy tutorial in the second half of this [Python NumPy tutorial](http://cs231n.github.io/python-numpy-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
    "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
    "    \n",
    "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
    "              number of co-occurring words.\n",
    "              \n",
    "              For example, if we take the document \"START All that glitters is not gold END\" with window size of 4,\n",
    "              \"All\" will co-occur with \"START\", \"that\", \"glitters\", \"is\", and \"not\".\n",
    "    \n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "            window_size (int): size of context window\n",
    "        Return:\n",
    "            M (numpy matrix of shape (number of corpus words, number of corpus words)): \n",
    "            Co-occurence matrix of word counts. \n",
    "            The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
    "            word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.)\n",
    "    \"\"\"\n",
    "    \n",
    "    words, num_words = distinct_words(corpus)\n",
    "    M = None\n",
    "    word2Ind = {}\n",
    "    \n",
    "    # A Matrix of zeros with shape (num_words, num_words)\n",
    "    M = np.zeros((num_words, num_words))\n",
    "    \n",
    "    for i in range(num_words):\n",
    "        word2Ind[words[i]] = i\n",
    "   \n",
    "    for line in corpus:\n",
    "        for i in range(len(line)):\n",
    "            target = line[i]\n",
    "            target_idx = word2Ind[target]\n",
    "            \n",
    "            #print('{} - {} - {} - {}'.format(target, target_idx, len(line), i))\n",
    "            \n",
    "            for j in range(max(i - window_size, 0), min(i + window_size + 1, len(line))):\n",
    "                if i != j and j >= i:\n",
    "                    M[target_idx][word2Ind[line[j]]] += 1\n",
    "                    M[word2Ind[line[j]]][target_idx] += 1\n",
    "            \n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct M:\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0. 1. 0.]]\n",
      "Your M: \n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0. 1. 0.]]\n",
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define toy corpus and get student's co-occurrence matrix\n",
    "test_corpus = [\"START All that glitters isn't gold END\".split(\" \"), \"START All's well that ends well END\".split(\" \")]\n",
    "M_test, word2Ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
    "\n",
    "# Correct M and word2Ind\n",
    "M_test_ans = np.array( \n",
    "    [[0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,],\n",
    "     [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,],\n",
    "     [0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,],\n",
    "     [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,],\n",
    "     [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,],\n",
    "     [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,],\n",
    "     [0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,],\n",
    "     [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,],\n",
    "     [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,],\n",
    "     [0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,]]\n",
    ")\n",
    "word2Ind_ans = {'All': 0, \"All's\": 1, 'END': 2, 'START': 3, 'ends': 4, 'glitters': 5, 'gold': 6, \"isn't\": 7, 'that': 8, 'well': 9}\n",
    "\n",
    "# Test correct word2Ind\n",
    "assert (word2Ind_ans == word2Ind_test), \"Your word2Ind is incorrect:\\nCorrect: {}\\nYours: {}\".format(word2Ind_ans, word2Ind_test)\n",
    "\n",
    "# Test correct M shape\n",
    "assert (M_test.shape == M_test_ans.shape), \"M matrix has incorrect shape.\\nCorrect: {}\\nYours: {}\".format(M_test.shape, M_test_ans.shape)\n",
    "\n",
    "# Test correct M values\n",
    "for w1 in word2Ind_ans.keys():\n",
    "    idx1 = word2Ind_ans[w1]\n",
    "    for w2 in word2Ind_ans.keys():\n",
    "        idx2 = word2Ind_ans[w2]\n",
    "        student = M_test[idx1, idx2]\n",
    "        correct = M_test_ans[idx1, idx2]\n",
    "        if student != correct:\n",
    "            print(\"Correct M:\")\n",
    "            print(M_test_ans)\n",
    "            print(\"Your M: \")\n",
    "            print(M_test)\n",
    "            raise AssertionError(\"Incorrect count at index ({}, {})=({}, {}) in matrix M. Yours has {} but should have {}.\".format(idx1, idx2, w1, w2, student, correct)) \n",
    "\n",
    "print(\"Correct M:\")\n",
    "print(M_test_ans)\n",
    "print(\"Your M: \")            \n",
    "print(M_test)\n",
    "      \n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
