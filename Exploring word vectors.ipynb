{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "Install gensim using the following command\n",
    "\n",
    "```pip install gensim```\n",
    "\n",
    "Install or update NLTK module\n",
    "\n",
    "```\n",
    "pip install --user -U nltk\n",
    "pip install --upgrade nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "***Reuters Corpus***\n",
    "\n",
    "The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into two sets, called \"training\" and \"test\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- https://www.nltk.org/install.html\n",
    "- https://www.nltk.org/data.html\n",
    "- https://www.nltk.org/book/ch02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/agoel/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import sys\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 5\n",
    "print(sys.version_info)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "# Download Reuters corpus from NLTK data distribution\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Reuters corpus\n",
    "\n",
    "Unlike the Brown Corpus, categories in the Reuters corpus overlap with each other, simply because a news story often covers multiple topics. We can ask for the topics covered by one or more documents, or for the documents included in one or more categories. For convenience, the corpus methods accept a single fileid or a list of fileids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', 'test/14840', 'test/14841', 'test/14842', 'test/14843']\n",
      "News documents count: 10788\n"
     ]
    }
   ],
   "source": [
    "# The text with fileid 'test/14826' is a document drawn from the test set.\n",
    "print(reuters.fileids()[0:10])\n",
    "# News document count\n",
    "print('News documents count: {}'.format(len(reuters.fileids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories count: 90\n",
      "\n",
      "Categories: ['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr']\n",
      "\n",
      "Categories in the document 'training/9865': ['barley', 'corn', 'grain', 'wheat']\n",
      "\n",
      "['test/15618', 'test/15649', 'test/15676', 'test/15728', 'test/15871', 'test/15875', 'test/15952', 'test/17767', 'test/17769', 'test/18024']\n",
      "\n",
      "Words by document/file: ['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', 'BIDS', 'DETAILED', 'French', 'operators', 'have', 'requested', 'licences', 'to', 'export']\n",
      "\n",
      "Words by categories: ['FRENCH', 'FREE', 'MARKET', 'CEREAL', 'EXPORT', ...]\n",
      "\n",
      "Words by multiple categories: ['THAI', 'TRADE', 'DEFICIT', 'WIDENS', 'IN', 'FIRST', ...]\n"
     ]
    }
   ],
   "source": [
    "print('categories count: {}'.format(len(reuters.categories())), end='\\n\\n')\n",
    "print('Categories: {}'.format(reuters.categories()[0:20]), end='\\n\\n')\n",
    "print('Categories in the document \\'training/9865\\': {}'.format(reuters.categories('training/9865')), end='\\n\\n')\n",
    "print(reuters.fileids('barley')[0:10], end='\\n\\n')\n",
    "print('Words by document/file: {}'.format(reuters.words('training/9865')[:14]), end='\\n\\n')\n",
    "print('Words by categories: {}'.format(reuters.words(categories='barley')), end='\\n\\n')\n",
    "print('Words by multiple categories: {}'.format(reuters.words(categories=['barley', 'corn'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurrence\n",
    "\n",
    "A co-occurrence matrix counts how often things co-occur in some environment. Given some word $w_i$  occurring in the document, we consider the context window surrounding $w_i$. Supposing our fixed window size is n, then this is the n preceding and n subsequent words in that document, i.e. words  $w_{i-n}…w_{i-1}$  and  $w_{i+1}…w_{i+n}$ . We build a co-occurrence matrix M, which is a symmetric word-by-word matrix in which  $M_{ij}$  is the number of times $w_{j}$ appears inside  $w_{i}$'s window.words\n",
    "\n",
    "***Example: Co-Occurrence with Fixed Window of n=1:***\n",
    "\n",
    "Document 1: \"all that glitters is not gold\"\n",
    "\n",
    "Document 2: \"all is well that ends well\"\n",
    "\n",
    "![title](static/co_occurence_matrix.png)\n",
    "\n",
    "\n",
    "The rows (or columns) of this matrix provide one type of word vectors (those based on word-word co-occurrence), but the vectors will be large in general (linear in the number of distinct words in a corpus). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Co-Occurrence Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(category='crude'):\n",
    "    \n",
    "    \"\"\" Read files from the specified Reuter's category.\n",
    "        Params:\n",
    "            category (string): category name\n",
    "        Return:\n",
    "            list of lists, with words from each of the processed files\n",
    "    \"\"\"\n",
    "    \n",
    "    files = reuters.fileids(category)\n",
    "    return [[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<START>', 'japan', 'to', 'revise', 'long', '-', 'term', 'energy', 'demand',\n",
      "  'downwards', 'the', 'ministry', 'of', 'international', 'trade', 'and', 'industry', '(',\n",
      "  'miti', ')', 'will', 'revise', 'its', 'long', '-', 'term', 'energy', 'supply', '/',\n",
      "  'demand', 'outlook', 'by', 'august', 'to', 'meet', 'a', 'forecast', 'downtrend', 'in',\n",
      "  'japanese', 'energy', 'demand', ',', 'ministry', 'officials', 'said', '.', 'miti', 'is',\n",
      "  'expected', 'to', 'lower', 'the', 'projection', 'for', 'primary', 'energy', 'supplies',\n",
      "  'in', 'the', 'year', '2000', 'to', '550', 'mln', 'kilolitres', '(', 'kl', ')', 'from',\n",
      "  '600', 'mln', ',', 'they', 'said', '.', 'the', 'decision', 'follows', 'the',\n",
      "  'emergence', 'of', 'structural', 'changes', 'in', 'japanese', 'industry', 'following',\n",
      "  'the', 'rise', 'in', 'the', 'value', 'of', 'the', 'yen', 'and', 'a', 'decline', 'in',\n",
      "  'domestic', 'electric', 'power', 'demand', '.', 'miti', 'is', 'planning', 'to', 'work',\n",
      "  'out', 'a', 'revised', 'energy', 'supply', '/', 'demand', 'outlook', 'through',\n",
      "  'deliberations', 'of', 'committee', 'meetings', 'of', 'the', 'agency', 'of', 'natural',\n",
      "  'resources', 'and', 'energy', ',', 'the', 'officials', 'said', '.', 'they', 'said',\n",
      "  'miti', 'will', 'also', 'review', 'the', 'breakdown', 'of', 'energy', 'supply',\n",
      "  'sources', ',', 'including', 'oil', ',', 'nuclear', ',', 'coal', 'and', 'natural',\n",
      "  'gas', '.', 'nuclear', 'energy', 'provided', 'the', 'bulk', 'of', 'japan', \"'\", 's',\n",
      "  'electric', 'power', 'in', 'the', 'fiscal', 'year', 'ended', 'march', '31', ',',\n",
      "  'supplying', 'an', 'estimated', '27', 'pct', 'on', 'a', 'kilowatt', '/', 'hour',\n",
      "  'basis', ',', 'followed', 'by', 'oil', '(', '23', 'pct', ')', 'and', 'liquefied',\n",
      "  'natural', 'gas', '(', '21', 'pct', '),', 'they', 'noted', '.', '<END>'],\n",
      " ['<START>', 'energy', '/', 'u', '.', 's', '.', 'petrochemical', 'industry', 'cheap',\n",
      "  'oil', 'feedstocks', ',', 'the', 'weakened', 'u', '.', 's', '.', 'dollar', 'and', 'a',\n",
      "  'plant', 'utilization', 'rate', 'approaching', '90', 'pct', 'will', 'propel', 'the',\n",
      "  'streamlined', 'u', '.', 's', '.', 'petrochemical', 'industry', 'to', 'record',\n",
      "  'profits', 'this', 'year', ',', 'with', 'growth', 'expected', 'through', 'at', 'least',\n",
      "  '1990', ',', 'major', 'company', 'executives', 'predicted', '.', 'this', 'bullish',\n",
      "  'outlook', 'for', 'chemical', 'manufacturing', 'and', 'an', 'industrywide', 'move',\n",
      "  'to', 'shed', 'unrelated', 'businesses', 'has', 'prompted', 'gaf', 'corp', '&', 'lt',\n",
      "  ';', 'gaf', '>,', 'privately', '-', 'held', 'cain', 'chemical', 'inc', ',', 'and',\n",
      "  'other', 'firms', 'to', 'aggressively', 'seek', 'acquisitions', 'of', 'petrochemical',\n",
      "  'plants', '.', 'oil', 'companies', 'such', 'as', 'ashland', 'oil', 'inc', '&', 'lt',\n",
      "  ';', 'ash', '>,', 'the', 'kentucky', '-', 'based', 'oil', 'refiner', 'and', 'marketer',\n",
      "  ',', 'are', 'also', 'shopping', 'for', 'money', '-', 'making', 'petrochemical',\n",
      "  'businesses', 'to', 'buy', '.', '\"', 'i', 'see', 'us', 'poised', 'at', 'the',\n",
      "  'threshold', 'of', 'a', 'golden', 'period', ',\"', 'said', 'paul', 'oreffice', ',',\n",
      "  'chairman', 'of', 'giant', 'dow', 'chemical', 'co', '&', 'lt', ';', 'dow', '>,',\n",
      "  'adding', ',', '\"', 'there', \"'\", 's', 'no', 'major', 'plant', 'capacity', 'being',\n",
      "  'added', 'around', 'the', 'world', 'now', '.', 'the', 'whole', 'game', 'is', 'bringing',\n",
      "  'out', 'new', 'products', 'and', 'improving', 'the', 'old', 'ones', '.\"', 'analysts',\n",
      "  'say', 'the', 'chemical', 'industry', \"'\", 's', 'biggest', 'customers', ',',\n",
      "  'automobile', 'manufacturers', 'and', 'home', 'builders', 'that', 'use', 'a', 'lot',\n",
      "  'of', 'paints', 'and', 'plastics', ',', 'are', 'expected', 'to', 'buy', 'quantities',\n",
      "  'this', 'year', '.', 'u', '.', 's', '.', 'petrochemical', 'plants', 'are', 'currently',\n",
      "  'operating', 'at', 'about', '90', 'pct', 'capacity', ',', 'reflecting', 'tighter',\n",
      "  'supply', 'that', 'could', 'hike', 'product', 'prices', 'by', '30', 'to', '40', 'pct',\n",
      "  'this', 'year', ',', 'said', 'john', 'dosher', ',', 'managing', 'director', 'of',\n",
      "  'pace', 'consultants', 'inc', 'of', 'houston', '.', 'demand', 'for', 'some', 'products',\n",
      "  'such', 'as', 'styrene', 'could', 'push', 'profit', 'margins', 'up', 'by', 'as', 'much',\n",
      "  'as', '300', 'pct', ',', 'he', 'said', '.', 'oreffice', ',', 'speaking', 'at', 'a',\n",
      "  'meeting', 'of', 'chemical', 'engineers', 'in', 'houston', ',', 'said', 'dow', 'would',\n",
      "  'easily', 'top', 'the', '741', 'mln', 'dlrs', 'it', 'earned', 'last', 'year', 'and',\n",
      "  'predicted', 'it', 'would', 'have', 'the', 'best', 'year', 'in', 'its', 'history', '.',\n",
      "  'in', '1985', ',', 'when', 'oil', 'prices', 'were', 'still', 'above', '25', 'dlrs', 'a',\n",
      "  'barrel', 'and', 'chemical', 'exports', 'were', 'adversely', 'affected', 'by', 'the',\n",
      "  'strong', 'u', '.', 's', '.', 'dollar', ',', 'dow', 'had', 'profits', 'of', '58', 'mln',\n",
      "  'dlrs', '.', '\"', 'i', 'believe', 'the', 'entire', 'chemical', 'industry', 'is',\n",
      "  'headed', 'for', 'a', 'record', 'year', 'or', 'close', 'to', 'it', ',\"', 'oreffice',\n",
      "  'said', '.', 'gaf', 'chairman', 'samuel', 'heyman', 'estimated', 'that', 'the', 'u',\n",
      "  '.', 's', '.', 'chemical', 'industry', 'would', 'report', 'a', '20', 'pct', 'gain',\n",
      "  'in', 'profits', 'during', '1987', '.', 'last', 'year', ',', 'the', 'domestic',\n",
      "  'industry', 'earned', 'a', 'total', 'of', '13', 'billion', 'dlrs', ',', 'a', '54',\n",
      "  'pct', 'leap', 'from', '1985', '.', 'the', 'turn', 'in', 'the', 'fortunes', 'of', 'the',\n",
      "  'once', '-', 'sickly', 'chemical', 'industry', 'has', 'been', 'brought', 'about', 'by',\n",
      "  'a', 'combination', 'of', 'luck', 'and', 'planning', ',', 'said', 'pace', \"'\", 's',\n",
      "  'john', 'dosher', '.', 'dosher', 'said', 'last', 'year', \"'\", 's', 'fall', 'in', 'oil',\n",
      "  'prices', 'made', 'feedstocks', 'dramatically', 'cheaper', 'and', 'at', 'the', 'same',\n",
      "  'time', 'the', 'american', 'dollar', 'was', 'weakening', 'against', 'foreign',\n",
      "  'currencies', '.', 'that', 'helped', 'boost', 'u', '.', 's', '.', 'chemical', 'exports',\n",
      "  '.', 'also', 'helping', 'to', 'bring', 'supply', 'and', 'demand', 'into', 'balance',\n",
      "  'has', 'been', 'the', 'gradual', 'market', 'absorption', 'of', 'the', 'extra',\n",
      "  'chemical', 'manufacturing', 'capacity', 'created', 'by', 'middle', 'eastern', 'oil',\n",
      "  'producers', 'in', 'the', 'early', '1980s', '.', 'finally', ',', 'virtually', 'all',\n",
      "  'major', 'u', '.', 's', '.', 'chemical', 'manufacturers', 'have', 'embarked', 'on',\n",
      "  'an', 'extensive', 'corporate', 'restructuring', 'program', 'to', 'mothball',\n",
      "  'inefficient', 'plants', ',', 'trim', 'the', 'payroll', 'and', 'eliminate', 'unrelated',\n",
      "  'businesses', '.', 'the', 'restructuring', 'touched', 'off', 'a', 'flurry', 'of',\n",
      "  'friendly', 'and', 'hostile', 'takeover', 'attempts', '.', 'gaf', ',', 'which', 'made',\n",
      "  'an', 'unsuccessful', 'attempt', 'in', '1985', 'to', 'acquire', 'union', 'carbide',\n",
      "  'corp', '&', 'lt', ';', 'uk', '>,', 'recently', 'offered', 'three', 'billion', 'dlrs',\n",
      "  'for', 'borg', 'warner', 'corp', '&', 'lt', ';', 'bor', '>,', 'a', 'chicago',\n",
      "  'manufacturer', 'of', 'plastics', 'and', 'chemicals', '.', 'another', 'industry',\n",
      "  'powerhouse', ',', 'w', '.', 'r', '.', 'grace', '&', 'lt', ';', 'gra', '>', 'has',\n",
      "  'divested', 'its', 'retailing', ',', 'restaurant', 'and', 'fertilizer', 'businesses',\n",
      "  'to', 'raise', 'cash', 'for', 'chemical', 'acquisitions', '.', 'but', 'some', 'experts',\n",
      "  'worry', 'that', 'the', 'chemical', 'industry', 'may', 'be', 'headed', 'for', 'trouble',\n",
      "  'if', 'companies', 'continue', 'turning', 'their', 'back', 'on', 'the', 'manufacturing',\n",
      "  'of', 'staple', 'petrochemical', 'commodities', ',', 'such', 'as', 'ethylene', ',',\n",
      "  'in', 'favor', 'of', 'more', 'profitable', 'specialty', 'chemicals', 'that', 'are',\n",
      "  'custom', '-', 'designed', 'for', 'a', 'small', 'group', 'of', 'buyers', '.', '\"',\n",
      "  'companies', 'like', 'dupont', '&', 'lt', ';', 'dd', '>', 'and', 'monsanto', 'co', '&',\n",
      "  'lt', ';', 'mtc', '>', 'spent', 'the', 'past', 'two', 'or', 'three', 'years', 'trying',\n",
      "  'to', 'get', 'out', 'of', 'the', 'commodity', 'chemical', 'business', 'in', 'reaction',\n",
      "  'to', 'how', 'badly', 'the', 'market', 'had', 'deteriorated', ',\"', 'dosher', 'said',\n",
      "  '.', '\"', 'but', 'i', 'think', 'they', 'will', 'eventually', 'kill', 'the', 'margins',\n",
      "  'on', 'the', 'profitable', 'chemicals', 'in', 'the', 'niche', 'market', '.\"', 'some',\n",
      "  'top', 'chemical', 'executives', 'share', 'the', 'concern', '.', '\"', 'the',\n",
      "  'challenge', 'for', 'our', 'industry', 'is', 'to', 'keep', 'from', 'getting', 'carried',\n",
      "  'away', 'and', 'repeating', 'past', 'mistakes', ',\"', 'gaf', \"'\", 's', 'heyman',\n",
      "  'cautioned', '.', '\"', 'the', 'shift', 'from', 'commodity', 'chemicals', 'may', 'be',\n",
      "  'ill', '-', 'advised', '.', 'specialty', 'businesses', 'do', 'not', 'stay', 'special',\n",
      "  'long', '.\"', 'houston', '-', 'based', 'cain', 'chemical', ',', 'created', 'this',\n",
      "  'month', 'by', 'the', 'sterling', 'investment', 'banking', 'group', ',', 'believes',\n",
      "  'it', 'can', 'generate', '700', 'mln', 'dlrs', 'in', 'annual', 'sales', 'by', 'bucking',\n",
      "  'the', 'industry', 'trend', '.', 'chairman', 'gordon', 'cain', ',', 'who', 'previously',\n",
      "  'led', 'a', 'leveraged', 'buyout', 'of', 'dupont', \"'\", 's', 'conoco', 'inc', \"'\", 's',\n",
      "  'chemical', 'business', ',', 'has', 'spent', '1', '.', '1', 'billion', 'dlrs', 'since',\n",
      "  'january', 'to', 'buy', 'seven', 'petrochemical', 'plants', 'along', 'the', 'texas',\n",
      "  'gulf', 'coast', '.', 'the', 'plants', 'produce', 'only', 'basic', 'commodity',\n",
      "  'petrochemicals', 'that', 'are', 'the', 'building', 'blocks', 'of', 'specialty',\n",
      "  'products', '.', '\"', 'this', 'kind', 'of', 'commodity', 'chemical', 'business', 'will',\n",
      "  'never', 'be', 'a', 'glamorous', ',', 'high', '-', 'margin', 'business', ',\"', 'cain',\n",
      "  'said', ',', 'adding', 'that', 'demand', 'is', 'expected', 'to', 'grow', 'by', 'about',\n",
      "  'three', 'pct', 'annually', '.', 'garo', 'armen', ',', 'an', 'analyst', 'with', 'dean',\n",
      "  'witter', 'reynolds', ',', 'said', 'chemical', 'makers', 'have', 'also', 'benefitted',\n",
      "  'by', 'increasing', 'demand', 'for', 'plastics', 'as', 'prices', 'become', 'more',\n",
      "  'competitive', 'with', 'aluminum', ',', 'wood', 'and', 'steel', 'products', '.',\n",
      "  'armen', 'estimated', 'the', 'upturn', 'in', 'the', 'chemical', 'business', 'could',\n",
      "  'last', 'as', 'long', 'as', 'four', 'or', 'five', 'years', ',', 'provided', 'the', 'u',\n",
      "  '.', 's', '.', 'economy', 'continues', 'its', 'modest', 'rate', 'of', 'growth', '.',\n",
      "  '<END>'],\n",
      " ['<START>', 'turkey', 'calls', 'for', 'dialogue', 'to', 'solve', 'dispute', 'turkey',\n",
      "  'said', 'today', 'its', 'disputes', 'with', 'greece', ',', 'including', 'rights', 'on',\n",
      "  'the', 'continental', 'shelf', 'in', 'the', 'aegean', 'sea', ',', 'should', 'be',\n",
      "  'solved', 'through', 'negotiations', '.', 'a', 'foreign', 'ministry', 'statement',\n",
      "  'said', 'the', 'latest', 'crisis', 'between', 'the', 'two', 'nato', 'members',\n",
      "  'stemmed', 'from', 'the', 'continental', 'shelf', 'dispute', 'and', 'an', 'agreement',\n",
      "  'on', 'this', 'issue', 'would', 'effect', 'the', 'security', ',', 'economy', 'and',\n",
      "  'other', 'rights', 'of', 'both', 'countries', '.', '\"', 'as', 'the', 'issue', 'is',\n",
      "  'basicly', 'political', ',', 'a', 'solution', 'can', 'only', 'be', 'found', 'by',\n",
      "  'bilateral', 'negotiations', ',\"', 'the', 'statement', 'said', '.', 'greece', 'has',\n",
      "  'repeatedly', 'said', 'the', 'issue', 'was', 'legal', 'and', 'could', 'be', 'solved',\n",
      "  'at', 'the', 'international', 'court', 'of', 'justice', '.', 'the', 'two', 'countries',\n",
      "  'approached', 'armed', 'confrontation', 'last', 'month', 'after', 'greece', 'announced',\n",
      "  'it', 'planned', 'oil', 'exploration', 'work', 'in', 'the', 'aegean', 'and', 'turkey',\n",
      "  'said', 'it', 'would', 'also', 'search', 'for', 'oil', '.', 'a', 'face', '-', 'off',\n",
      "  'was', 'averted', 'when', 'turkey', 'confined', 'its', 'research', 'to', 'territorrial',\n",
      "  'waters', '.', '\"', 'the', 'latest', 'crises', 'created', 'an', 'historic',\n",
      "  'opportunity', 'to', 'solve', 'the', 'disputes', 'between', 'the', 'two', 'countries',\n",
      "  ',\"', 'the', 'foreign', 'ministry', 'statement', 'said', '.', 'turkey', \"'\", 's',\n",
      "  'ambassador', 'in', 'athens', ',', 'nazmi', 'akiman', ',', 'was', 'due', 'to', 'meet',\n",
      "  'prime', 'minister', 'andreas', 'papandreou', 'today', 'for', 'the', 'greek', 'reply',\n",
      "  'to', 'a', 'message', 'sent', 'last', 'week', 'by', 'turkish', 'prime', 'minister',\n",
      "  'turgut', 'ozal', '.', 'the', 'contents', 'of', 'the', 'message', 'were', 'not',\n",
      "  'disclosed', '.', '<END>']]\n"
     ]
    }
   ],
   "source": [
    "reuters_corpus = read_corpus()\n",
    "pprint.pprint(reuters_corpus[:3], compact=True, width=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find distinct words in a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a method to work out the distinct words (word types) that occur in the corpus. We can do this with for loops, but it's more efficient to do it with Python list comprehensions. In particular, please refer to [this](http://web.stanford.edu/class/cs224n/assignments/a1_preview/exploring_word_vectors.html) to flatten a list of lists. For more information on list comprehensions, please refer [here](https://coderwall.com/p/rcmaea/flatten-a-list-of-lists-in-one-line-in-python)\n",
    "\n",
    "You may find it useful to use [Python sets](https://www.w3schools.com/python/python_sets.asp) to remove duplicate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_words(corpus):\n",
    "    \n",
    "    \"\"\" Determine a list of distinct words for the corpus.\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "        Return:\n",
    "            corpus_words (list of strings): list of distinct words across the corpus, sorted (using python 'sorted' function)\n",
    "            num_corpus_words (integer): number of distinct words across the corpus\n",
    "    \"\"\"\n",
    "    corpus_words = []\n",
    "    num_corpus_words = -1\n",
    "    \n",
    "    \"\"\"List comprehensions are cleaner and faster than the for loop\n",
    "       A set is a collection which is unordered, unindexed and contains unique elements. \n",
    "      In Python sets are written with curly brackets.\n",
    "    \"\"\"\n",
    "    corpus_set = {w for s in corpus for w in s}\n",
    "    sorted_corpus_set = sorted(corpus_set)\n",
    "    corpus_words = sorted_corpus_set\n",
    "    num_corpus_words = len(corpus_words)\n",
    "    \n",
    "    return corpus_words, num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define toy corpus\n",
    "test_corpus = [\"START All that glitters isn't gold END\".split(\" \"), \"START All's well that ends well END\".split(\" \")]\n",
    "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
    "\n",
    "# Correct answers\n",
    "ans_test_corpus_words = sorted(list(set([\"START\", \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", \"END\"])))\n",
    "ans_num_corpus_words = len(ans_test_corpus_words)\n",
    "\n",
    "# Test correct number of words\n",
    "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
    "\n",
    "# Test correct words\n",
    "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours:   {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
    "\n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute co-occurence matrix\n",
    "\n",
    "Below is a method that constructs a co-occurrence matrix for a certain window-size n (with a default of 4), considering words n  before and n  after the word in the center of the window. Here, we will use numpy (np) to represent vectors, matrices, and tensors. If  not familiar with NumPy, there's a NumPy tutorial in the second half of this [Python NumPy tutorial](http://cs231n.github.io/python-numpy-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
    "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
    "    \n",
    "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
    "              number of co-occurring words.\n",
    "              \n",
    "              For example, if we take the document \"START All that glitters is not gold END\" with window size of 4,\n",
    "              \"All\" will co-occur with \"START\", \"that\", \"glitters\", \"is\", and \"not\".\n",
    "    \n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "            window_size (int): size of context window\n",
    "        Return:\n",
    "            M (numpy matrix of shape (number of corpus words, number of corpus words)): \n",
    "            Co-occurence matrix of word counts. \n",
    "            The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
    "            word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.)\n",
    "    \"\"\"\n",
    "    \n",
    "    words, num_words = distinct_words(corpus)\n",
    "    M = None\n",
    "    word2Ind = {}\n",
    "    \n",
    "    # A Matrix of zeros with shape (num_words, num_words)\n",
    "    M = np.zeros((num_words, num_words))\n",
    "    \n",
    "    for i in range(num_words):\n",
    "        word2Ind[words[i]] = i\n",
    "   \n",
    "    for line in corpus:\n",
    "        for i in range(len(line)):\n",
    "            target = line[i]\n",
    "            target_idx = word2Ind[target]\n",
    "            \n",
    "            #print('{} - {} - {} - {}'.format(target, target_idx, len(line), i))\n",
    "            \n",
    "            for j in range(max(i - window_size, 0), min(i + window_size + 1, len(line))):\n",
    "                if i != j and j >= i:\n",
    "                    M[target_idx][word2Ind[line[j]]] += 1\n",
    "                    M[word2Ind[line[j]]][target_idx] += 1\n",
    "            \n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct M:\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0. 1. 0.]]\n",
      "Your M: \n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0. 1. 0.]]\n",
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define toy corpus and get student's co-occurrence matrix\n",
    "test_corpus = [\"START All that glitters isn't gold END\".split(\" \"), \"START All's well that ends well END\".split(\" \")]\n",
    "M_test, word2Ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
    "\n",
    "# Correct M and word2Ind\n",
    "M_test_ans = np.array( \n",
    "    [[0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,],\n",
    "     [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,],\n",
    "     [0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,],\n",
    "     [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,],\n",
    "     [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,],\n",
    "     [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,],\n",
    "     [0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,],\n",
    "     [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,],\n",
    "     [1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,],\n",
    "     [0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,]]\n",
    ")\n",
    "word2Ind_ans = {'All': 0, \"All's\": 1, 'END': 2, 'START': 3, 'ends': 4, 'glitters': 5, 'gold': 6, \"isn't\": 7, 'that': 8, 'well': 9}\n",
    "\n",
    "# Test correct word2Ind\n",
    "assert (word2Ind_ans == word2Ind_test), \"Your word2Ind is incorrect:\\nCorrect: {}\\nYours: {}\".format(word2Ind_ans, word2Ind_test)\n",
    "\n",
    "# Test correct M shape\n",
    "assert (M_test.shape == M_test_ans.shape), \"M matrix has incorrect shape.\\nCorrect: {}\\nYours: {}\".format(M_test.shape, M_test_ans.shape)\n",
    "\n",
    "# Test correct M values\n",
    "for w1 in word2Ind_ans.keys():\n",
    "    idx1 = word2Ind_ans[w1]\n",
    "    for w2 in word2Ind_ans.keys():\n",
    "        idx2 = word2Ind_ans[w2]\n",
    "        student = M_test[idx1, idx2]\n",
    "        correct = M_test_ans[idx1, idx2]\n",
    "        if student != correct:\n",
    "            print(\"Correct M:\")\n",
    "            print(M_test_ans)\n",
    "            print(\"Your M: \")\n",
    "            print(M_test)\n",
    "            raise AssertionError(\"Incorrect count at index ({}, {})=({}, {}) in matrix M. Yours has {} but should have {}.\".format(idx1, idx2, w1, w2, student, correct)) \n",
    "\n",
    "print(\"Correct M:\")\n",
    "print(M_test_ans)\n",
    "print(\"Your M: \")            \n",
    "print(M_test)\n",
    "      \n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce to K dimensions\n",
    "\n",
    "Below method performs dimensionality reduction on the matrix to produce k-dimensional embeddings. Use Singular value decomposition(SVD) to take the top k components and produce a new matrix of k-dimensional embeddings.\n",
    "\n",
    "***Note:*** All of numpy, scipy, and scikit-learn (sklearn) provide some implementation of SVD, but only scipy and sklearn provide an implementation of Truncated SVD, and only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD. So we'll use [sklearn.decomposition.TruncatedSVD.](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_k_dim(M, k=2):\n",
    "    \"\"\" Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)\n",
    "        to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:\n",
    "            - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "    \n",
    "        Params:\n",
    "            M (numpy matrix of shape (number of corpus words, number of corpus words)): co-occurence matrix of word counts\n",
    "            k (int): embedding size of each word after dimension reduction\n",
    "        Return:\n",
    "            M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.\n",
    "                    In terms of the SVD from maths, this actually returns U * S\n",
    "    \"\"\"    \n",
    "    \n",
    "    n_iters = 10\n",
    "    M_reduced = None\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    \n",
    "    # Fit Latent semantic indexing (LSI) model to X and perform dimensionality reduction on X.\n",
    "    M_reduced = svd.fit_transform(M)\n",
    "    \n",
    "    print('Done.')\n",
    "    return M_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "[[ 7.05647176e-01  4.84057274e-01]\n",
      " [ 7.05647176e-01 -4.84057274e-01]\n",
      " [ 6.54802087e-01 -7.83221122e-01]\n",
      " [ 5.20200324e-01  2.38490293e-14]\n",
      " [ 1.02780472e+00 -1.87006520e-14]\n",
      " [ 6.54802087e-01  7.83221122e-01]\n",
      " [ 3.82258491e-01  6.56224003e-01]\n",
      " [ 3.82258491e-01 -6.56224003e-01]\n",
      " [ 1.39420808e+00 -1.06179274e+00]\n",
      " [ 1.39420808e+00  1.06179274e+00]]\n",
      "--------------------------------------------------------------------------------\n",
      "Passed All Tests!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this not an exhaustive check for correctness \n",
    "# In fact we only check that your M_reduced has the right dimensions.\n",
    "# ---------------------\n",
    "\n",
    "# Define toy corpus and run student code\n",
    "test_corpus = [\"START All that glitters isn't gold END\".split(\" \"), \"START All's well that ends well END\".split(\" \")]\n",
    "M_test, word2Ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
    "M_test_reduced = reduce_to_k_dim(M_test, k=2)\n",
    "\n",
    "# Test proper dimensions\n",
    "assert (M_test_reduced.shape[0] == 10), \"M_reduced has {} rows; should have {}\".format(M_test_reduced.shape[0], 10)\n",
    "assert (M_test_reduced.shape[1] == 2), \"M_reduced has {} columns; should have {}\".format(M_test_reduced.shape[1], 2)\n",
    "\n",
    "print(M_test_reduced)\n",
    "\n",
    "# Print Success\n",
    "print (\"-\" * 80)\n",
    "print(\"Passed All Tests!\")\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Embeddings\n",
    "\n",
    "Below is a function to plot a set of 2D vectors in 2D space. For graphs, we used Matplotlib (plt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(M_reduced, word2Ind, words):\n",
    "    \"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
    "        NOTE: do not plot all the words listed in M_reduced / word2Ind.\n",
    "        Include a label next to each point.\n",
    "        \n",
    "        Params:\n",
    "            M_reduced (numpy matrix of shape (number of unique words in the corpus , k)): matrix of k-dimensioal word embeddings\n",
    "            word2Ind (dict): dictionary that maps word to indices for matrix M\n",
    "            words (list of strings): words whose embeddings we want to visualize\n",
    "    \"\"\"\n",
    "      \n",
    "    for i, w in enumerate(words):\n",
    "        x = M_reduced[word2Ind[w]][0]\n",
    "        y = M_reduced[word2Ind[w]][1]\n",
    "        plt.scatter(x, y, marker='o', color='r')\n",
    "        plt.text(x+0.001, y+0.001, w)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Outputted Plot:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# Run this sanity check\n",
    "# Note that this not an exhaustive check for correctness.\n",
    "# The plot produced should look like the \"test solution plot\" depicted below. \n",
    "# ---------------------\n",
    "\n",
    "print (\"-\" * 80)\n",
    "print (\"Outputted Plot:\")\n",
    "\n",
    "M_reduced_plot_test = np.array([[1, 1], [-1, -1], [1, -1], [-1, 1], [0, 0]])\n",
    "word2Ind_plot_test = {'test1': 0, 'test2': 1, 'test3': 2, 'test4': 3, 'test5': 4}\n",
    "words = ['test1', 'test2', 'test3', 'test4', 'test5']\n",
    "plot_embeddings(M_reduced_plot_test, word2Ind_plot_test, words)\n",
    "\n",
    "print (\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurence Plot analysis\n",
    "\n",
    "Now, using the above functions, we will compute the co-occurrence matrix with fixed window of 4, over the Reuters \"crude\" corpus. Then we will use TruncatedSVD to compute 2-dimensional embeddings of each word. TruncatedSVD returns U*S, so we normalize the returned vectors, so that all the vectors will appear around the unit circle (therefore closeness is directional closeness). ***Note:*** Below, normalization is performed using the NumPy concept of broadcasting. For more info on broadcasting, please refer - [Computation on Arrays: Broadcasting by Jake VanderPlas](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "[[ 0.98750922 -0.15756126]\n",
      " [ 0.99184346 -0.12746193]\n",
      " [ 0.97435476  0.22501733]\n",
      " ...\n",
      " [ 0.95936334 -0.28217366]\n",
      " [ 0.98010883 -0.19846079]\n",
      " [ 0.99559598  0.09374777]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Run This Cell to Produce the Plot\n",
    "# ------------------------------\n",
    "reuters_corpus = read_corpus()\n",
    "M_co_occurrence, word2Ind_co_occurrence = compute_co_occurrence_matrix(reuters_corpus)\n",
    "M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k=2)\n",
    "\n",
    "# Rescale (normalize) the rows to make them each of unit-length\n",
    "M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis=1)\n",
    "M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # broadcasting\n",
    "\n",
    "print(M_normalized)\n",
    "\n",
    "words = ['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'venezuela']\n",
    "plot_embeddings(M_normalized, word2Ind_co_occurrence, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction based word-vectors - word2Vec\n",
    "\n",
    "More recently prediction-based word vectors have come into fashion, e.g. word2vec. Below, we will explore the embeddings produced by word2vec. Please refer [original paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec():\n",
    "    \"\"\" Load Word2Vec Vectors\n",
    "        Return:\n",
    "            wv_from_bin: All 3 million embeddings, each lengh 300\n",
    "    \"\"\"\n",
    "    import gensim.downloader as api\n",
    "    wv_from_bin = api.load(\"word2vec-google-news-300\")\n",
    "    vocab = list(wv_from_bin.vocab.keys())\n",
    "    print(\"Loaded vocab size %i\" % len(vocab))\n",
    "    return wv_from_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Run Cell to Load Word Vectors\n",
    "# Note: This may take several minutes\n",
    "# -----------------------------------\n",
    "wv_from_bin = load_word2vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing dimensionality of Word2Vec Word Embeddings\n",
    "\n",
    "Now, we'll compare the word2vec embeddings to those of the co-occurrence matrix. Run the following cells to:\n",
    "\n",
    "1. Put the 3 million word2vec vectors into a matrix M\n",
    "2. Run reduce_to_k_dim (your Truncated SVD function) to reduce the vectors from 300-dimensional to 2-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_of_vectors(wv_from_bin, required_words=['barrels', 'bpd', 'ecuador', 'energy', 'industry', 'kuwait', 'oil', 'output', 'petroleum', 'venezuela']):\n",
    "    \"\"\" Put the word2vec vectors into a matrix M.\n",
    "        Param:\n",
    "            wv_from_bin: KeyedVectors object; the 3 million word2vec vectors loaded from file\n",
    "        Return:\n",
    "            M: numpy matrix shape (num words, 300) containing the vectors\n",
    "            word2Ind: dictionary mapping each word to its row number in M\n",
    "    \"\"\"\n",
    "    import random\n",
    "    words = list(wv_from_bin.vocab.keys())\n",
    "    print(\"Shuffling words ...\")\n",
    "    random.shuffle(words)\n",
    "    words = words[:10000]\n",
    "    print(\"Putting %i words into word2Ind and matrix M...\" % len(words))\n",
    "    word2Ind = {}\n",
    "    M = []\n",
    "    curInd = 0\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(wv_from_bin.word_vec(w))\n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    for w in required_words:\n",
    "        try:\n",
    "            M.append(wv_from_bin.word_vec(w))\n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    M = np.stack(M)\n",
    "    print(\"Done.\")\n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Run this Cell to Reduce 300-Dimensinal Word Embeddings to k Dimensions\n",
    "# Note: This may take several minutes\n",
    "# -----------------------------------------------------------------\n",
    "M, word2Ind = get_matrix_of_vectors(wv_from_bin)\n",
    "M_reduced = reduce_to_k_dim(M, k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
